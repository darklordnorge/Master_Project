\chapter{Background \& Objectives}

%write about evolutionary robotics

\section{Aim of this project}
The goal of this project is to create a program that controls a swarm of E-Puck robots in order to map an environment. \\
The E-Pucks always need to stay in communication, as they share a global map. \\
The control algorithm is an Artificial Neural Network, a evolutionary algorithm. \\
The neural network is trained so that it will learn to develop a solution on its own.
The benefit of neural networks are that they are extremely versatile. A trained neural network will perform very good even in an different environment. Neural networks also allow for quick reactions of robots with very little processing time once they are fully evolved.  

\section{Information about the project}
\subsection{Choice of development environment and programming language}
Since the control algorithm for the robots is an artificial neural network its needs to be trained before it can be tested. Therefore a simulator is needed.
The simulator chosen for this project has been created by Elio Tuci(elt7@aber.ac.uk) and Muhanad Hayder Mohammed(mhm4@aber.ac.uk) at Aberystwyth University. \\
The other candidate was Cyberbotics Webots\footnote{\url{http://goo.gl/BrPK98}}. \\
The simulator by Elio Tuci was chosen since I worked with it throughout the second semester of this master course and therefore know it well. Other reasons include that simulator is build for the creation of evolutionary algorithms and already posses an implemented genetic algorithm. \\
At the beginning of the project it was deemed ambitious to create a working genetic algorithm as well as artificial neural network and train it to perform the tasks explained in this chapter. \\
The programming language chosen for this project is C++ as the simulator is written in it. 

\subsection{Choice of robot}
The E-Puck\footnote{\url{http://www.e-puck.org/index.php}} robot was chosen for this project as it is commercially available and versatile. \\
The \textit{standard} robot comes with 8 IR proximity sensors placed at different intervals around the robot. It is powered by lithium-ion battery that is easily chargeable. 2 stepper motors allows it too move\cite{mondada2009puck}. \\

Since the project is done in an simulator no direct worries need to be done for battery life, though such could be simulated by calculating battery usage. This is however not done for the sake of this project. \\

The E-Puck is also useful as there is a wide range of extensions boards available to it, and its bus interface makes it possible and easy to design and add extension boards. \\
For this project the official Range and Bearing Board is used, more info about that can be found in section \ref{chap1:communication}\cite{Gutierrez}.

\subsection{Choice of environment design}
An environment was designed to train the artificial neural network.\\
The environment represents a large room through which the robot swarm moves. There are multiple obstacles placed throughout the room to train and test the swarms communication and mapping abilities. A representation of the created environment can be found in Appendix  \ref{appendix2:environment} on page \pageref{appendix2:environment}. \\




\section{Analysis}

\subsection{Communications}
\label{chap1:communication}
The Communication capabilities of the E-Puck where analysed. The Standard E-Puck comes  with bluetooth communication and posses now WiFi capabilities. \\
Bluetooth  communication for this project has been deemed infeasible as Bluetooth communications can take somewhere around 19.5 $\pm$ 4 seconds. A multi robot exploration and mapping project such as this requires almost constant communication, in which case bluetooth connection times of \~19 seconds are too long.\\

There are a few proposed ways to implement WiFi communications on the e-puck robot. 
One of the methods was proposed by Christopher M. Cianci \textit{et al.}\cite{Cianci2007Communication} is the creation and implementation of a WiFi extension board for the e-puck, enabling communication between ZigBee and other IEEE 802.15.4 compliant transceivers. \\
There designed communication board is based on the MSP430 Microcontroller\footnote{\url{http://www.ti.com/product/msp430f169}} and the Chipcon CC2420\footnote{http://www.ti.com/product/cc2420} radio.\\
Allowing the e-puck a communication range between 15cm and 5 meters. \\
However such an board is not commercially available and would need to be custom designed and build, which is outside the spectrum of this project.

For the purposes of this project the use of the official e-puck range and bearing board has been deemed appropriate, as it is would be commercially available.\\
The range and bearing board is an extension board for the E-Puck which allows for localisation and local communication between E-Pucks using infra-red transmission. 
The board is powered by its own processor and consists of 12 sets of IR emission/reception modules. 
The board was first designed and build by GuiÃªrrez \textit{et al.}\cite{Gutierrez}. 

\subsection{Control Algorithm}
The control algorithm for this project is an artificial neural network assisted by an genetic algorithm.\\
The background and use of those will be explain in further detail in this section.

\subsubsection{Artificial Neural Network}
The control algorithm used for this project is an artificial neural network(ANN).
Artificial neural networks are inspired by the brain. \\
A biological brain functions by passing electrical signals through nodes, so called neurons. Neurons of the brain can be compared to simple Input/Output connectors which transmit pulse coded analogue information. The relation between a the inputs and outputs can be displayed a simple sigmoid function\cite{Hopfield}.\\
To a neuron not all inputs are the same however, different inputs(i.e. outputs from other neurons) have stronger influence on it than others, in neuroscience this is defined as synaptic weights. \\
This influence can be trained, in the course of a life a neuron \textit{learns} to trust some inputs more than others, the same training is done in an artificial neural network. The synaptic weights are represented by the \textit{weight} value each link between 2 nodes holds. This weight value is calculated and evolved using a genetic algorithm. 

\subsubsection{Genetic Algorithm}
Genetic Algorithms(GA) are a evolutionary algorithm inspired by the genetics of living organism. \\
An GA works by having a population  of genes, which make out an chromosome. The genes in regard to this GA represent the weights used in the neural network. \\
A chromosome is constructed as followed, the first 1 gene holds a number representing the genotype length, in other words the number of genes in this chromosome and thereby the number of weights in the neural network. This number is calculated when the neural network is created at the start of the program and passed along to the GA.\\
The following genes represent each a weight for a specific link between 2 nodes in the neural network. The value is a number between 0 and 1. \\
The last gene in the chromosome holds the fitness assigned to this chromosome, which is calculated using the fitness function.\\

An genetic algorithms modifies the genes using operators which mimic their biological counterpart. \\

The genetic modifier described as \textit{crossover} switches genes in chromosome to vary the genetic pool between generations. \\
This crossover can be done with either single genes, or groups of genes depending on the implementation, and of course any restrictions based on the nature of the data. \\

The other operator is mutation, which is the possibility that a random gene switches its value to another random value.\\
Which genes are chosen for crossover is based on the selection method implemented in the algorithm. \\
The third major part of an GA is the selection method, the method that is used to choose which chromosomes of the gene pool should carried over into the next generation.\\
The selection method implemented in this simulator is \textit{Roulette Wheel Selection}. 
This selection method is part of the \textit{Proportionate Reproduction} scheme this reproduction scheme chooses individuals to be carried over into the next generation based on their objective fitness function \cite{goldberg1991comparative}. 

The basic part of the selection process is that the fittest individuals have the highest change to be carried over. This replicated nature in a way that a fitter individual tends to have a higher change of survival and will go forward to the mating pool of the next generation.\\
However weaker individuals(chromosomes) are not without a probabilistic change to get selected. 
It is called roulette wheel selection because its graphical representation is similar to a roulette wheel, as figure \ref{fig:selection} shows\cite{1631619}.

\begin{figure}[h]
\begin{center}
\includegraphics[scale=0.4]{Chapter1/images/roulette_wheel.png} 
\caption[Roulette Wheel Selection]{Roulette Wheel Selection\footnotemark}
\label{fig:selection}
\end{center}
\end{figure} 

\footnotetext{Image credit: Newcastle University Engineering and Design Center, accessed 7th of September 2015 \url{http://goo.gl/uwMSVB}}

As can be seen in figure \ref{fig:selection} individuals with a higher fitness occupy a large of the overall available area. \\

\subsection{Fitness Function}
A fitness function is used to guide the evolution of the neural network and the GA. It is used to rate the performance of a neural network based on a predefined formulae or criterion.\\
The baseline for the fitness function implemented in this project was proposed by Floreano \textit{et al.}\cite{499791}. \\
This fitness function is a good baseline as it prevents the robot from stopping, spinning on the spot, and crashing into obstacles, but still being close enough to an obstacle to get a positive return(obstacle found) from at least 1 sensor reading. \\
This fitness function was expanded upon as new features where implemented to lead to more complex behaviour of the robot.\\
The final fitness function is shown and explained in Chapter \ref{chap2:fitness_function} on page \pageref{chap2:fitness_function}.

\subsection{Localisation}
In real life scenarios GPS information is not always available, especially when mapping the insight of buildings. \\
For the sake of this project the localisation and rotation readings are taken from the simulator. \\

While not realistic a time shortage prevented further development of a localisation algorithm.\\
Thought went into to question of localisation and there are a couple of approaches which could be taken in future work to incorporate them. \\
One of the approaches is to use odometry, in which the robots position and location is calculated using the knowledge of how many steps the stepper motors did between readings and the wheel diameter of the robots wheels. Knowing how many \textit{steps} equal a full rotation, in case of the E-Pucks motors this is 20 steps\footnote{e-puck.org webside, accessed 8th of September, 2015,, \url{http://goo.gl/YpQ2nf}}, and the diameter of the robots wheels, around 41mm\footnote{e-puck.org webside, accessed 8th of September, 2015, \url{http://goo.gl/YpQ2nf}}, allows to calculate what distance the robot has driven in a straight line. \\

The rotation of a robot can be calculated using the same data combined with the knowledge of the robots wheelbase.\\
However odometry is not a perfect localisation method. Uncertainty about for example the robots wheel diameter, or a wrongly calibrated stepper motor can throw of the location and rotation calculation completely. In real world applications, or simulators which simulate real world properties such as friction between the wheels and the floor, can cause additional problems. \\
This \textit{error} in the calculation and movement get bigger overtime unless the localisation and rotation values stored in the robots memory are reset at certain intervals. In order to be able to reset it however exact knowledge of the location in the world is needed, not something possible in all environments.\\
Therefore odometry can be at best be seen as an estimate of the robots location and rotation. 

Another possible approach is to locate a robot using another robots sensor, such as the IR sensors on the range and bearing board. \\
However without prior knowledge of where the \textit{searching} robot is in the world it is impossible to calculate the location of the \textit{searched after} robot, only it distance and bearing from the \textit{searching} robot. \\
This knowledge might be enough for some applications, however there are also limits to the localisation possibilities using this approach.
IR sensors beams widen over distance, meaning the error of an bearings reading increases over distance. Therefore there is a a limit to over how large distances a robots location can be calculated using this. 

Thoughts went also in to combining both the odometry calculations with the range and bearing information of the robot, however a shortage of time let to that no method was implemented in the system. 


\subsection{Mapping}
To map the environment the E-Pucks IR sensors are used. \\
Using the knowledge of the robots position as well as the sensor read out it is possible to calculate the position of an obstacle in regard to the robot. \\

\begin{figure}[h]
\begin{center}
\includegraphics[scale=0.4]{Chapter1/images/e_puck_sensor.png}
\caption{E-Puck sensor placement}
\label{fig:sensor_placement} 
\end{center}
\end{figure}

Figure \ref{fig:sensor_placement} shows the placement of the robots IR sensors, labelled \textit{ps0} through \textit{ps7}.\\
With the knowledge of where a particular sensor is placed on the robot combined with the knowledge of the robots position, rotation and the return of the IR reading, it is possible to calculate the placement of a obstacle in the environment.\\

The robots all share a single global map, which is updated with the position of all robots, as well as the position of any encountered obstacles, at each iteration. \\
The map it self a standard occupancy grid map: a 2 dimensional grid where each cell can have 1 of 3 possible values: 0 = unexplored, 1 = obstacle, 2 = robot position.  

\section{Process}
The life cycle model used for this project is "Feature Driven Development" (FDD) as it seems the more appropriate for this project than other models, such as extreme programming or test driven development. \\
The reason FDD is more appropriate is that this is a single person project, as well as the requirements allowed for easy distinguish in which order features need to be implemented.  \\
For example: the controller(neural network) needs to be implemented to be able to train it. Once the it is implemented and the robots are able to move based on its control, the communication between the robots can be implemented. Only once this is done and tested the mapping algorithm can be started to be developed, as the features build on each other.\\

The milestones of the project rather small and incremental "upgrades" on each other. For example the fitness function went from "move in certain direction" to "move in a certain direction and avoid obstacles" to much later "move throughout the environment, don't spin at the same spot, avoid crashing into obstacles but be close enough to map them and stay in communication range with other robots". \\
 


