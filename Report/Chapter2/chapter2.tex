%\addcontentsline{toc}{chapter}{Development Process}
\chapter{Design}



\section{Overall Architecture}
\subsection{Control Algorithm}
In this section the design of the control algorithm will be explained.

\subsection{Artificial Neural Network}
The robot swarm is controlled by an artificial neural network. \\
The neural network is consistent of 8 inputs, 3 hidden nodes, and 4 outputs. \\
There are bias nodes connected to the hidden and output layer, both of which are always set to 1. \\
A representation of the network is shown in figure \ref{fig:ann}. 
The ANN is a multilayer feed forward network, meaning all layers nodes are connected to all nodes in the following layer and that data is only passed forward in the network, never back as would be the case using a different type of neural network, like a backpropagation algorithm. \\

The inputs are taken from the E-Pucks 8 IR proximity sensors. The hidden layer consists of 3 hidden nodes, which give more computational depth to the network. \\
From the 4 outputs of the neural the speed of the 2 stepper motors of the e-puck are calculated. This is done by calculating the difference between them. \\
The weights of the neural network are generated by a Genetic algorithm, which is part of the used simulator. The genes created by the GA are a value between 0 and 1, however the neural network algorithm scales them to be be a value between -5 and 5.\\ 
The reason for scaling is explained in section \ref{sec:hiddenlayer} of this chapter.\\

%explain reason for scalling
%use geogebra to draw a sigmoid function and explain  creater activation function spread 


The bias is needed to be able to shift the entire sigmoid function along the \textit{x} axis. 

\begin{figure}[h]
\begin{center}
\includegraphics[scale=0.3]{Chapter2/images/bias.png}
\caption[Representation of a shifting sigmoid function]{Representation of a shifting sigmoid function\footnotemark}
\label{fig:bias}
\end{center}
\end{figure}

\footnotetext{Image credit Stackoverflow, accessed 8th of September, 2015 \url{http://goo.gl/Vktx0X}}

\begin{figure}[h]
\begin{center}
\includegraphics[scale=0.3]{Chapter2/images/network.png}
\end{center}
\caption{Representation of the Neural Network}
\label{fig:ann}
\end{figure}


\subsubsection{Input Layer}
The inputs to the ANN are returned from the E-Pucks 8 IR sensors and are a value between 0 and 4096.\\

\begin{figure}[h]
\begin{center}
\includegraphics[scale=0.3]{Chapter2/images/Selection_002.png} 
\caption[IR sensor response against distance]{IR sensor response against distance\footnotemark}
\label{fig:ir_distance}
\end{center}
\end{figure} 

\footnotetext{Image credit: Webots User Guide \url{http://goo.gl/kyCINM}}

As can be in the in figure \ref{fig:ir_distance} the returned IR sensors value rises drastically after the robot comes closer to an obstacle than 3 centimetres. \\


\subsubsection{Hidden Layer \& Sigmoid Function}\label{sec:hiddenlayer}
In the hidden layer the sum of all inputs to a node is multiplied by the weights to that node and than fed to sigmoid function.\\

A sigmoid function refers to a mathematical function that has an "S"(sigmoid) shape.\\
A sigmoid, or activation function, is an abstract representation of a neuron firing(activating) in the brain. There are a number of different approaches to activation functions, the simplest is a simple binary step function, with only 2 stages: \textit{on} or \textit{off}.\\
The activation function in this neural network is a sigmoid function which is given by:

\begin{equation}
S(x) = \frac{1}{1 + e^{-x}}
\end{equation} 

Where $e$ represents \textit{Euler's number} which is 2.71828[...] and $x$ represents the input to the function, in this case the sum of all inputs multiplied by the weights.\\
The output of the sigmoid function is a number between 0 and 1.\\

Sufficient scaling of inputs is important as it increases the \textit{range} of the activation functions calculation. \\
Figure  \ref{fig:unscaled} shows a graphical representation of  this sigmoid function. The red lines represent the range on which an activation can happen if the inputs are between 0 and 1. Figure \ref{fig:scaled} however shows the area of activation if the inputs are between -5 and 5. The graph shows that scaled inputs have a higher activation range which leads to better performing networks. 

\begin{figure}[h]
\begin{center}
\includegraphics[scale=0.4]{Chapter2/images/unscaled.PNG}
\caption{Activation range for unscaled inputs}
\label{fig:unscaled}
\end{center}
\end{figure}

\begin{figure}[h]
\begin{center}
\includegraphics[scale=0.4]{Chapter2/images/scaled.PNG}
\caption{Activation range for scaled inputs}
\label{fig:scaled}
\end{center}
\end{figure}

\subsubsection{Output Layer}
In the outputlayer the outputs from the hiddenlayer are multiplied with their respective weights, and than passed to a sigmoid function again.\\
The output of the layer are than send back to the experiment class.\\
The velocity which will be set for each wheel is calculated by the difference between the 2 of the nodes. 
The \textit{first} 2 nodes are used to calculate the velocity for the left wheel, the \textit{last} 2 nodes for the right wheel. 

\subsection{Fitness Function}\label{chap2:fitness_function}
The fitness function is used to guide the evolution towards to the best solution.\\
The fitness function used in this project is as follows:

\begin{equation}\label{eq:full_fittness}
f = mean(V_l, V_r) \times (1 - \sqrt[•]{|V_l - V_r|}) \times (1 - S_{ir}) \times coms \times pos_z
\end{equation}

Where $V_l$ and $V_r$ represent the velocity of the left and right wheel, $S_ir$ represents the highest IR sensor reading of the that iteration, $coms$ represent the robots distance to a another robot in the swarm. $pos_z$ represents the z position of the robot. \\
This is a modified version of a fitness function proposed by Floreano \textit{et al.}\cite{499791}. \\
Their fitness function, as is shown in equation \ref{eq:base_fittness}, covers the basic movement rules for a robot. 

\begin{equation}\label{eq:base_fittness}
f = mean(V_l, V_r) \times ( 1 - \sqrt[•]{|V_l - V_r|}) \times (1 - S_{ir})
\end{equation}

In this equation the values are normalized to fit:
\begin{align*}
	0  &\leq V \leq 1 \\  
	0  &\leq \Delta V  \leq 1 \\
	0  &\leq S_{ir} \leq 1
\end{align*}

Where V is the velocity of a wheel, here 0 would mean full speed backwards and 1 full speed forwards. Stand still is represented by a value of 0.5.\\
$\Delta V$ represents the absolute difference between the left and right wheel velocities. \\
The IR reading $S_{ir}$ is normalized to a number between 0 and 1, where 1 would mean the robot is very close to an object, 0 would mean the sensor has no return at all, i.e. no object is in range. However the simulator introduces noise into system, similar to how there would be noise in a real world application. Therefore this value will never be exactly 0. \\
The standard values of the velocity are all in a range from -1 to 1 and have been normalized to 0 to 1 in order to ensure that the fitness function works properly \cite{499791}.  \\
The rationality behind the different \textit{segments} of the fitness function is a follows: 
$mean(V_l, V_r)$ is the average between the velocities, this ensures that the robot does not stand still as stopping would prevent the fitness value of increasing. This is also means that the fitness is increasing when the robot is turning. \\
$1 - \sqrt[•]{|V_l - V_r|}$ motivates the robots to move in a straight line rather than driving in large circles. \\
$1 - S_{ir}$ does reward the robot for not crashing into walls as the normalized function does return 1 when the robot is close to colliding with an obstacle, this would mean this sub-calculation would return 0. \\
$coms$ represents the the distance between it and another robot. The higher the value the better, this prevents the robots from driving close to each other, and gets them to drive at the full extent of their communication range. If the robots pass a certain distance this value is set to 0. 
%write about hte last step in the fitness funciton 

\subsection{Genetic Algorithm}
The genetic algorithm was not implemented for the sake of this project, it is build into the simulator. Therefore only the parameters used for the GA and their effect on the evolution process will be covered here \\
The GA parameters used for this:\\

\begin{table}[h]
\begin{center}
\begin{tabular}{l r}
Number of Chromosomes & 100 \\
Number of Elite & 20\\
Probability of Mutation & 5\%\\
Probability of Crossover & 30\%\\
\end{tabular}
\caption{Genetic Algorithm Parameters}
\end{center}
\end{table}

The number of chromosomes defines the size of the gene pool. \\
A number of 100 chromosomes are generated each generation. Of those an elite of 20 chromosomes with the best assigned fitness function is chosen using the roulette wheel selection method to be taken to the next generation.\\
A gene has a 30\% change to be selected to be part of a crossover operation.
All genes have also a 5\% change to be mutated. 

\section{Program set up}
The user specifies the user environment and other simulator parameters, such as how many robots to use, how many generations to evolve, iteration length per generation, where and how often to save genomes. \\

A UML representation of the program can be seen in appendix B section \ref{appendixB:uml} from page \pageref{appendixB:uml} and onward. \\
Note that due the size of the classes it was not able to represent all of them in one large figure, and still be able to read them.\\
Therefore the UML diagram has been split up into multiple figures. 
Figure \ref{fig:simple_uml} represents a very simplified class diagram without functions or member variables, it only shows the relationship between the different classes.\\
The classes shown in this representation are not all classes used in the simulator, they are however all classes that have been actively used or been modified by the author in the course of this project.\\
As the other classes of the simulator have not been modified or accessed they are treated as an blackbox and excluded from this report.\\
Figures \ref{fig:exp_uml}, \ref{fig:param_uml}, \ref{fig:agent_uml} and \ref{fig:controller_uml} represent the UML diagrams for the experiment, parameter, simple\_agent, and mycontroller classes.\\

The parameter class reads the parameter file in which the user specifies program parameters such as how many generations should been run, how many evaluations and iterations per generation, as well as defining the environment.\\
This class also handles the genetic algorithm and the neural network, and the agents.\\
The SIMPLE\_Agent class represents the variables and functions available to the robots. The parameter class creates as many agents as specified by the user.\\

MyController class holds the neural network and inherits variables and methods from the Controller superclass.\\
The user can change the number of hidden nodes in the MyController header file. \\
The EXP\_Class is the class where a user set's up the experiment, and from where the experiment is handled. In this class the fitness function is defined.\\
Occupancy\_Map class holds the variables and function needed to create and manipulate the map.\\
EXP\_Class holds a single occupancy\_map object, the map.

\section{Mapping algorithm}
\subsection{Mapping procedure}
The mapping algorithm works by locating the robot, using the simulators inbuilt functions. \\
The robots share a global map, the map itself is a 2D occupancy grid. Where each cell can have one of 3 possible values:\\

\begin{table}[h]
\begin{center}
\begin{tabular}{l c r}
0 & = & Unexplored \\
1 & = & Occupied \\
2 & = & Robot's Position \\
\end{tabular}
\end{center}
\end{table}

The entire map is initialised to be 0 in the beginning. For this project each cell is defined as a space a robot can move through. \\
If a robot is located only partially between 2 cells, its location will be rounded or down, depending on its coordinates, so that at it is always assumed that the complete robot is inside a cell.\\

To map the right cells it is important about to know the heading of the robot. This is done by taken the robots rotation and assigning one of pre-defined headings to it based on it. \\
The possible headings are inspired by compass direction and are: North, East, South, West, North-East, South-East, South-West, North-West.\\
Once the robots position and heading are known surrounding cells can be marked based on the IR sensors readings. Since a cell has a the same dimensions as a robot(which has a diameter of 70 mm, and the IR sensor has a range of about 4cm(where an obstacle can still be located with any form of certainty, see figure \ref{fig:ir_distance} on page \pageref{fig:ir_distance} for more information, the robot is only able to map any cells adjacent to the cell occupied by the robot. \\
Knowledge of the robot's sensor placement allows for easy determinate which cell to mark as occupied based on the IR sensor activation value. \\

\begin{table}[h]
\begin{center}
\begin{tabular}{c | c | c}
PS6 & PS7 \& PS0 & PS1 \\\hline
 & $\uparrow$ & \\
PS5 & Robot Heading & PS2 \\\hline
 & PS4 \& PS3 & 
\end{tabular}
\caption{Correlation between map cells and Robot sensors}
\label{tab:cells}
\end{center}
\end{table}

Table \ref{tab:cells} shows a representation of how robot sensors correlate to to the adjacent cells of where the robot is located. Here \textit{PS} stands for \textit{proximity sensor} followed by the sensor number. See figure \ref{fig:sensor_placement} on page \pageref{fig:sensor_placement} for a graphical representation of the E-Puck robot and its sensors.  \\
Knowing the robots location, heading, and sensor activation a cell is easily modified using by taken the robots X and Y coordinates and increasing or decreasing both of them to correspond with the cell which needs to be marked. This is done using the above representation as guideline. \\
Every iteration each robot marks its position on the map with '2' and each found occupied cell as '1'.\\

\subsection{Map visualisation}
In order do visualize the map, the X and Y coordinates of all cells marked with '1' are saved to a text file.\\
This file can be loaded into a different program and be visualized using the C++ SDL2 library.
